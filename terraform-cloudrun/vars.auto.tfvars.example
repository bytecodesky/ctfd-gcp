# Example Terraform variables for Cloud Run CTFd deployment
# Copy this file to vars.auto.tfvars and edit with your values

# === REQUIRED ===

# Your GCP project ID (must already exist or be created separately)
project_id = "my-ctf-project"

# Domain name for your CTFd instance (must be managed in Cloudflare or your DNS provider)
# This will be used for the managed SSL certificate
domain = "ctf.example.com"

# === OPTIONAL (defaults provided) ===

# GCP region for all resources
# region = "us-central1"

# Location for GCS bucket (US, EU, or ASIA)
# bucket_location = "US"

# CIDR ranges for networking
# main_subnet_cidr      = "10.0.0.0/24"      # Main VPC subnet
# access_connector_cidr = "10.8.0.0/28"      # Serverless VPC Access connector (must be /28)

# CTFd Cloud Run configuration
# ctfd = {
#   image           = "ctfd/ctfd:3.7.0"      # CTFd Docker image
#   min_instances   = 1                       # Minimum number of instances (always running)
#   max_instances   = 10                      # Maximum instances for autoscaling
#   cpu             = "2"                     # CPU allocation (1, 2, 4, etc.)
#   memory          = "2Gi"                   # Memory allocation (512Mi, 1Gi, 2Gi, 4Gi, etc.)
#   max_concurrency = 80                      # Max concurrent requests per instance
# }

# Cloud SQL Postgres configuration
# db = {
#   tier              = "db-custom-2-7680"   # Machine type (2 vCPU, 7.68GB RAM)
#   disk_size_gb      = 20                    # Disk size in GB
#   availability_type = "REGIONAL"            # "REGIONAL" for HA, "ZONAL" for single-zone
#   postgres_version  = "POSTGRES_15"         # PostgreSQL version (15, 16, etc.)
# }

# Memorystore Redis configuration
# redis = {
#   memory_size_gb = 2                        # Redis memory in GB
#   tier           = "STANDARD_HA"            # "STANDARD_HA" for HA, "BASIC" for single-node
# }

# GCS bucket prefix for uploads (will append project_id)
# s3_bucket_prefix = "ctfd-uploads"
